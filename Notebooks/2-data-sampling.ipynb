{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>index</th>\n",
       "      <th>url-id</th>\n",
       "      <th>age</th>\n",
       "      <th>sex</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>428</td>\n",
       "      <td>47.0</td>\n",
       "      <td>male</td>\n",
       "      <td>arabic</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>421</td>\n",
       "      <td>21.0</td>\n",
       "      <td>male</td>\n",
       "      <td>uk</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "      <td>420</td>\n",
       "      <td>26.0</td>\n",
       "      <td>female</td>\n",
       "      <td>usa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>9</td>\n",
       "      <td>419</td>\n",
       "      <td>21.0</td>\n",
       "      <td>male</td>\n",
       "      <td>uk</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>12</td>\n",
       "      <td>416</td>\n",
       "      <td>19.0</td>\n",
       "      <td>male</td>\n",
       "      <td>usa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1468</th>\n",
       "      <td>1468</td>\n",
       "      <td>3086</td>\n",
       "      <td>442</td>\n",
       "      <td>38.0</td>\n",
       "      <td>female</td>\n",
       "      <td>usa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1469</th>\n",
       "      <td>1469</td>\n",
       "      <td>3087</td>\n",
       "      <td>441</td>\n",
       "      <td>18.0</td>\n",
       "      <td>male</td>\n",
       "      <td>spanish</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1470</th>\n",
       "      <td>1470</td>\n",
       "      <td>3089</td>\n",
       "      <td>439</td>\n",
       "      <td>31.0</td>\n",
       "      <td>male</td>\n",
       "      <td>uk</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1471</th>\n",
       "      <td>1471</td>\n",
       "      <td>3091</td>\n",
       "      <td>437</td>\n",
       "      <td>40.0</td>\n",
       "      <td>male</td>\n",
       "      <td>arabic</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1472</th>\n",
       "      <td>1472</td>\n",
       "      <td>3098</td>\n",
       "      <td>430</td>\n",
       "      <td>29.0</td>\n",
       "      <td>male</td>\n",
       "      <td>mandarin</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1473 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Unnamed: 0  index  url-id   age     sex     label\n",
       "0              0      0     428  47.0    male    arabic\n",
       "1              1      7     421  21.0    male        uk\n",
       "2              2      8     420  26.0  female       usa\n",
       "3              3      9     419  21.0    male        uk\n",
       "4              4     12     416  19.0    male       usa\n",
       "...          ...    ...     ...   ...     ...       ...\n",
       "1468        1468   3086     442  38.0  female       usa\n",
       "1469        1469   3087     441  18.0    male   spanish\n",
       "1470        1470   3089     439  31.0    male        uk\n",
       "1471        1471   3091     437  40.0    male    arabic\n",
       "1472        1472   3098     430  29.0    male  mandarin\n",
       "\n",
       "[1473 rows x 6 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"speech-accent-archive-march-version.csv\")\n",
    "df.rename(columns={'accent': 'label'}, inplace=True)\n",
    "df = df.dropna()\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "female    769\n",
       "male      703\n",
       "Name: sex, dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['sex'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>url-id</th>\n",
       "      <th>age</th>\n",
       "      <th>sex</th>\n",
       "      <th>label</th>\n",
       "      <th>age-group</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>428</td>\n",
       "      <td>47.0</td>\n",
       "      <td>male</td>\n",
       "      <td>arabic</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>421</td>\n",
       "      <td>21.0</td>\n",
       "      <td>male</td>\n",
       "      <td>uk</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>420</td>\n",
       "      <td>26.0</td>\n",
       "      <td>female</td>\n",
       "      <td>usa</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>419</td>\n",
       "      <td>21.0</td>\n",
       "      <td>male</td>\n",
       "      <td>uk</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>416</td>\n",
       "      <td>19.0</td>\n",
       "      <td>male</td>\n",
       "      <td>usa</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1468</th>\n",
       "      <td>442</td>\n",
       "      <td>38.0</td>\n",
       "      <td>female</td>\n",
       "      <td>usa</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1469</th>\n",
       "      <td>441</td>\n",
       "      <td>18.0</td>\n",
       "      <td>male</td>\n",
       "      <td>spanish</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1470</th>\n",
       "      <td>439</td>\n",
       "      <td>31.0</td>\n",
       "      <td>male</td>\n",
       "      <td>uk</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1471</th>\n",
       "      <td>437</td>\n",
       "      <td>40.0</td>\n",
       "      <td>male</td>\n",
       "      <td>arabic</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1472</th>\n",
       "      <td>430</td>\n",
       "      <td>29.0</td>\n",
       "      <td>male</td>\n",
       "      <td>mandarin</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1472 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      url-id   age     sex     label age-group\n",
       "0        428  47.0    male    arabic         3\n",
       "1        421  21.0    male        uk         1\n",
       "2        420  26.0  female       usa         2\n",
       "3        419  21.0    male        uk         1\n",
       "4        416  19.0    male       usa         1\n",
       "...      ...   ...     ...       ...       ...\n",
       "1468     442  38.0  female       usa         3\n",
       "1469     441  18.0    male   spanish         1\n",
       "1470     439  31.0    male        uk         2\n",
       "1471     437  40.0    male    arabic         3\n",
       "1472     430  29.0    male  mandarin         2\n",
       "\n",
       "[1472 rows x 5 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Dividing the dataset into 3 age groups\n",
    "df['age-group'] = pd.qcut(df['age'], 3, labels=[1, 2, 3])\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         label     sex age-group  count\n",
      "0       arabic  female         1     31\n",
      "1       arabic  female         2     39\n",
      "2       arabic  female         3     20\n",
      "3       arabic    male         1     36\n",
      "4       arabic    male         2     34\n",
      "5       arabic    male         3     40\n",
      "6        dutch  female         1     22\n",
      "7        dutch  female         2      2\n",
      "8        dutch  female         3      8\n",
      "9        dutch    male         1      9\n",
      "10       dutch    male         2      2\n",
      "11       dutch    male         3     11\n",
      "12      french  female         1     20\n",
      "13      french  female         2     10\n",
      "14      french  female         3     17\n",
      "15      french    male         1     14\n",
      "16      french    male         2      8\n",
      "17      french    male         3     16\n",
      "18      korean  female         1     30\n",
      "19      korean  female         2     11\n",
      "20      korean  female         3     20\n",
      "21      korean    male         1     10\n",
      "22      korean    male         2     17\n",
      "23      korean    male         3      9\n",
      "24    mandarin  female         1     37\n",
      "25    mandarin  female         2     50\n",
      "26    mandarin  female         3     13\n",
      "27    mandarin    male         1     25\n",
      "28    mandarin    male         2     26\n",
      "29    mandarin    male         3      5\n",
      "30  portuguese  female         1     12\n",
      "31  portuguese  female         2     13\n",
      "32  portuguese  female         3     11\n",
      "33  portuguese    male         1     14\n",
      "34  portuguese    male         2     12\n",
      "35  portuguese    male         3      7\n",
      "36     russian  female         1     12\n",
      "37     russian  female         2     23\n",
      "38     russian  female         3     14\n",
      "39     russian    male         1     10\n",
      "40     russian    male         2     11\n",
      "41     russian    male         3     11\n",
      "42     spanish  female         1     25\n",
      "43     spanish  female         2     35\n",
      "44     spanish  female         3     54\n",
      "45     spanish    male         1     36\n",
      "46     spanish    male         2     46\n",
      "47     spanish    male         3     39\n",
      "48          uk  female         1      9\n",
      "49          uk  female         2      4\n",
      "50          uk  female         3     11\n",
      "51          uk    male         1     16\n",
      "52          uk    male         2     10\n",
      "53          uk    male         3     20\n",
      "54         usa  female         1     88\n",
      "55         usa  female         2     49\n",
      "56         usa  female         3     79\n",
      "57         usa    male         1     78\n",
      "58         usa    male         2     54\n",
      "59         usa    male         3     77\n"
     ]
    }
   ],
   "source": [
    "# Creating groups to see if stratification on age is possible with the dataset - it is not really\n",
    "grouped_df = df.groupby(['label', 'sex', 'age-group']).size().reset_index(name='count')\n",
    "print(grouped_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    534\n",
       "3    482\n",
       "2    456\n",
       "Name: age-group, dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['age-group'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function dividing the dataset into training, validation and testing sets\n",
    "\n",
    "def train_test_validation_split(df, test_per_label=6, validation_per_label=6, random_state=None):\n",
    "    # Set the random seed for reproducible results\n",
    "    if random_state is not None:\n",
    "        np.random.seed(random_state)\n",
    "\n",
    "    # Initialize empty DataFrames for the test and validation sets\n",
    "    test_df = pd.DataFrame(columns=df.columns)\n",
    "    validation_df = pd.DataFrame(columns=df.columns)\n",
    "    \n",
    "    # Loop through each label\n",
    "    for label in df[\"label\"].unique():\n",
    "        # Get a subset of the DataFrame containing only rows with the current label\n",
    "        label_df = df[df[\"label\"] == label]\n",
    "        \n",
    "        # Loop through each unique pair of sex and age-group\n",
    "        for sex in label_df[\"sex\"].unique():\n",
    "            for age_group in label_df[\"age-group\"].unique():\n",
    "                # Get a subset of the label DataFrame containing only rows with the current sex and age-group\n",
    "                subset = label_df[(label_df[\"sex\"] == sex) & (label_df[\"age-group\"] == age_group)]\n",
    "\n",
    "                # If the subset is not empty, randomly sample one row and add it to the test DataFrame\n",
    "                if not subset.empty:\n",
    "                    sample = subset.sample(1)\n",
    "                    test_df = test_df.append(sample)\n",
    "                    # Remove the selected row from the original DataFrame\n",
    "                    df = df.drop(sample.index)\n",
    "\n",
    "        # Calculate the number of rows needed to complete the test_per_label constraint\n",
    "        remaining_samples = test_per_label - len(test_df[test_df[\"label\"] == label])\n",
    "\n",
    "        # If there are remaining samples needed, randomly select them from the label DataFrame\n",
    "        if remaining_samples > 0:\n",
    "            sample = label_df.sample(remaining_samples)\n",
    "            test_df = test_df.append(sample)\n",
    "            # Remove the selected rows from the original DataFrame\n",
    "            df = df.drop(sample.index)\n",
    "\n",
    "    # Repeat the process for the validation set\n",
    "    for label in df[\"label\"].unique():\n",
    "        label_df = df[df[\"label\"] == label]\n",
    "        for sex in label_df[\"sex\"].unique():\n",
    "            for age_group in label_df[\"age-group\"].unique():\n",
    "                subset = label_df[(label_df[\"sex\"] == sex) & (label_df[\"age-group\"] == age_group)]\n",
    "                if not subset.empty:\n",
    "                    sample = subset.sample(1)\n",
    "                    validation_df = validation_df.append(sample)\n",
    "                    df = df.drop(sample.index)\n",
    "\n",
    "        remaining_samples = validation_per_label - len(validation_df[validation_df[\"label\"] == label])\n",
    "        if remaining_samples > 0:\n",
    "            sample = label_df.sample(remaining_samples)\n",
    "            validation_df = validation_df.append(sample)\n",
    "            df = df.drop(sample.index)\n",
    "\n",
    "    # Add a new column \"set\" to the train, test, and validation DataFrames\n",
    "    df[\"set\"] = \"train\"\n",
    "    test_df[\"set\"] = \"test\"\n",
    "    validation_df[\"set\"] = \"validation\"\n",
    "\n",
    "    # Concatenate the train, test, and validation DataFrames\n",
    "    result_df = pd.concat([df, test_df, validation_df], ignore_index=True)\n",
    "\n",
    "    return result_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_df = train_test_validation_split(df, test_per_label=6, validation_per_label=6, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>url-id</th>\n",
       "      <th>age</th>\n",
       "      <th>sex</th>\n",
       "      <th>label</th>\n",
       "      <th>age-group</th>\n",
       "      <th>set</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>428</td>\n",
       "      <td>47.0</td>\n",
       "      <td>male</td>\n",
       "      <td>arabic</td>\n",
       "      <td>3</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>421</td>\n",
       "      <td>21.0</td>\n",
       "      <td>male</td>\n",
       "      <td>uk</td>\n",
       "      <td>1</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>420</td>\n",
       "      <td>26.0</td>\n",
       "      <td>female</td>\n",
       "      <td>usa</td>\n",
       "      <td>2</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>419</td>\n",
       "      <td>21.0</td>\n",
       "      <td>male</td>\n",
       "      <td>uk</td>\n",
       "      <td>1</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>412</td>\n",
       "      <td>21.0</td>\n",
       "      <td>male</td>\n",
       "      <td>french</td>\n",
       "      <td>1</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1467</th>\n",
       "      <td>1484</td>\n",
       "      <td>25.0</td>\n",
       "      <td>male</td>\n",
       "      <td>dutch</td>\n",
       "      <td>2</td>\n",
       "      <td>validation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1468</th>\n",
       "      <td>1275</td>\n",
       "      <td>22.0</td>\n",
       "      <td>male</td>\n",
       "      <td>dutch</td>\n",
       "      <td>1</td>\n",
       "      <td>validation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1469</th>\n",
       "      <td>770</td>\n",
       "      <td>54.0</td>\n",
       "      <td>female</td>\n",
       "      <td>dutch</td>\n",
       "      <td>3</td>\n",
       "      <td>validation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1470</th>\n",
       "      <td>2989</td>\n",
       "      <td>28.0</td>\n",
       "      <td>female</td>\n",
       "      <td>dutch</td>\n",
       "      <td>2</td>\n",
       "      <td>validation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1471</th>\n",
       "      <td>1740</td>\n",
       "      <td>21.0</td>\n",
       "      <td>female</td>\n",
       "      <td>dutch</td>\n",
       "      <td>1</td>\n",
       "      <td>validation</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1472 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     url-id   age     sex   label age-group         set\n",
       "0       428  47.0    male  arabic         3       train\n",
       "1       421  21.0    male      uk         1       train\n",
       "2       420  26.0  female     usa         2       train\n",
       "3       419  21.0    male      uk         1       train\n",
       "4       412  21.0    male  french         1       train\n",
       "...     ...   ...     ...     ...       ...         ...\n",
       "1467   1484  25.0    male   dutch         2  validation\n",
       "1468   1275  22.0    male   dutch         1  validation\n",
       "1469    770  54.0  female   dutch         3  validation\n",
       "1470   2989  28.0  female   dutch         2  validation\n",
       "1471   1740  21.0  female   dutch         1  validation\n",
       "\n",
       "[1472 rows x 6 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "train         210\n",
       "test            3\n",
       "validation      3\n",
       "Name: set, dtype: int64"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result_df[(result_df['label'] == \"usa\") & (result_df['sex'] == \"female\")][\"set\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "arabic        3\n",
       "uk            3\n",
       "usa           3\n",
       "french        3\n",
       "spanish       3\n",
       "russian       3\n",
       "portuguese    3\n",
       "mandarin      3\n",
       "korean        3\n",
       "dutch         3\n",
       "Name: label, dtype: int64"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result_df[(result_df['set']==\"test\") & (result_df['sex']==\"male\")][\"label\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Deciding which samples go into the n-f-n dataset (in the thesis this was called dataset A)\n",
    "\n",
    "def sampler_n_f_n(df):\n",
    "    # Initialize the n-f-n column with False values\n",
    "    df[\"n-f-n\"] = False\n",
    "\n",
    "    # Loop through each label\n",
    "    for label in df[\"label\"].unique():\n",
    "        # Get a subset of the DataFrame containing only rows with the current label and \"train\" set\n",
    "        label_df = df[(df[\"label\"] == label) & (df[\"set\"] == \"train\")]\n",
    "\n",
    "        # Calculate the number of rows to sample (minimum of 100 or the number of rows in label_df)\n",
    "        num_samples = min(100, len(label_df))\n",
    "\n",
    "        # Randomly sample rows from the label_df\n",
    "        sampled_indices = label_df.sample(num_samples).index\n",
    "\n",
    "        # Set the \"n-f-n\" column to True for the sampled rows\n",
    "        df.loc[sampled_indices, \"n-f-n\"] = True\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>url-id</th>\n",
       "      <th>age</th>\n",
       "      <th>sex</th>\n",
       "      <th>label</th>\n",
       "      <th>age-group</th>\n",
       "      <th>set</th>\n",
       "      <th>n-f-n</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>428</td>\n",
       "      <td>47.0</td>\n",
       "      <td>male</td>\n",
       "      <td>arabic</td>\n",
       "      <td>3</td>\n",
       "      <td>train</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>421</td>\n",
       "      <td>21.0</td>\n",
       "      <td>male</td>\n",
       "      <td>uk</td>\n",
       "      <td>1</td>\n",
       "      <td>train</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>420</td>\n",
       "      <td>26.0</td>\n",
       "      <td>female</td>\n",
       "      <td>usa</td>\n",
       "      <td>2</td>\n",
       "      <td>train</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>419</td>\n",
       "      <td>21.0</td>\n",
       "      <td>male</td>\n",
       "      <td>uk</td>\n",
       "      <td>1</td>\n",
       "      <td>train</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>412</td>\n",
       "      <td>21.0</td>\n",
       "      <td>male</td>\n",
       "      <td>french</td>\n",
       "      <td>1</td>\n",
       "      <td>train</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1467</th>\n",
       "      <td>1484</td>\n",
       "      <td>25.0</td>\n",
       "      <td>male</td>\n",
       "      <td>dutch</td>\n",
       "      <td>2</td>\n",
       "      <td>validation</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1468</th>\n",
       "      <td>1275</td>\n",
       "      <td>22.0</td>\n",
       "      <td>male</td>\n",
       "      <td>dutch</td>\n",
       "      <td>1</td>\n",
       "      <td>validation</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1469</th>\n",
       "      <td>770</td>\n",
       "      <td>54.0</td>\n",
       "      <td>female</td>\n",
       "      <td>dutch</td>\n",
       "      <td>3</td>\n",
       "      <td>validation</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1470</th>\n",
       "      <td>2989</td>\n",
       "      <td>28.0</td>\n",
       "      <td>female</td>\n",
       "      <td>dutch</td>\n",
       "      <td>2</td>\n",
       "      <td>validation</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1471</th>\n",
       "      <td>1740</td>\n",
       "      <td>21.0</td>\n",
       "      <td>female</td>\n",
       "      <td>dutch</td>\n",
       "      <td>1</td>\n",
       "      <td>validation</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1472 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     url-id   age     sex   label age-group         set  n-f-n\n",
       "0       428  47.0    male  arabic         3       train   True\n",
       "1       421  21.0    male      uk         1       train   True\n",
       "2       420  26.0  female     usa         2       train  False\n",
       "3       419  21.0    male      uk         1       train   True\n",
       "4       412  21.0    male  french         1       train   True\n",
       "...     ...   ...     ...     ...       ...         ...    ...\n",
       "1467   1484  25.0    male   dutch         2  validation  False\n",
       "1468   1275  22.0    male   dutch         1  validation  False\n",
       "1469    770  54.0  female   dutch         3  validation  False\n",
       "1470   2989  28.0  female   dutch         2  validation  False\n",
       "1471   1740  21.0  female   dutch         1  validation  False\n",
       "\n",
       "[1472 rows x 7 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result_df_with_n_f_n = sampler_n_f_n(result_df)\n",
    "result_df_with_n_f_n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "arabic        100\n",
       "spanish       100\n",
       "mandarin      100\n",
       "usa           100\n",
       "korean         85\n",
       "french         73\n",
       "russian        69\n",
       "uk             58\n",
       "portuguese     57\n",
       "dutch          42\n",
       "Name: label, dtype: int64"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result_df_with_n_f_n[result_df_with_n_f_n[\"n-f-n\"] == True][\"label\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dediding how many times each speaker gets sampled for the s-f-o (aka C) dataset\n",
    "\n",
    "def sampler_s_f_o(df):\n",
    "    # Initialize the s-f-o column with value 1 for each row\n",
    "    df[\"s-f-o\"] = 1\n",
    "\n",
    "    # Set s-f-o to 0 for testing and validation rows\n",
    "    df.loc[df[\"set\"] != \"train\", \"s-f-o\"] = 0\n",
    "\n",
    "    # Define the target sum for each label - sex pair\n",
    "    target_sum = 210\n",
    "\n",
    "    # Loop until the sum of s-f-o for each label - sex pair in the training set reaches the target sum\n",
    "    while True:\n",
    "        # Initialize a boolean flag to track if any pair is still below the target sum\n",
    "        below_target = False\n",
    "\n",
    "        # Loop through each label\n",
    "        for label in df[\"label\"].unique():\n",
    "            # Loop through each sex\n",
    "            for sex in df[\"sex\"].unique():\n",
    "                # Get a subset of the DataFrame containing only rows with the current label and sex in the training set\n",
    "                subset = df[(df[\"label\"] == label) & (df[\"sex\"] == sex) & (df[\"set\"] == \"train\")]\n",
    "\n",
    "                # Calculate the current sum of s-f-o for the label - sex pair\n",
    "                current_sum = subset[\"s-f-o\"].sum()\n",
    "\n",
    "                # If the current sum is below the target sum\n",
    "                if current_sum < target_sum:\n",
    "                    # Set the below_target flag to True\n",
    "                    below_target = True\n",
    "\n",
    "                    # Randomly sample a row from the subset\n",
    "                    sampled_index = subset.sample(1).index\n",
    "\n",
    "                    # Increment the s-f-o value for the sampled row\n",
    "                    df.loc[sampled_index, \"s-f-o\"] += 1\n",
    "\n",
    "        # If none of the label - sex pairs in the training set are below the target sum, break the loop\n",
    "        if not below_target:\n",
    "            break\n",
    "\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>url-id</th>\n",
       "      <th>age</th>\n",
       "      <th>sex</th>\n",
       "      <th>label</th>\n",
       "      <th>age-group</th>\n",
       "      <th>set</th>\n",
       "      <th>n-f-n</th>\n",
       "      <th>s-f-o</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>428</td>\n",
       "      <td>47.0</td>\n",
       "      <td>male</td>\n",
       "      <td>arabic</td>\n",
       "      <td>3</td>\n",
       "      <td>train</td>\n",
       "      <td>True</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>421</td>\n",
       "      <td>21.0</td>\n",
       "      <td>male</td>\n",
       "      <td>uk</td>\n",
       "      <td>1</td>\n",
       "      <td>train</td>\n",
       "      <td>True</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>420</td>\n",
       "      <td>26.0</td>\n",
       "      <td>female</td>\n",
       "      <td>usa</td>\n",
       "      <td>2</td>\n",
       "      <td>train</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>419</td>\n",
       "      <td>21.0</td>\n",
       "      <td>male</td>\n",
       "      <td>uk</td>\n",
       "      <td>1</td>\n",
       "      <td>train</td>\n",
       "      <td>True</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>412</td>\n",
       "      <td>21.0</td>\n",
       "      <td>male</td>\n",
       "      <td>french</td>\n",
       "      <td>1</td>\n",
       "      <td>train</td>\n",
       "      <td>True</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1467</th>\n",
       "      <td>1484</td>\n",
       "      <td>25.0</td>\n",
       "      <td>male</td>\n",
       "      <td>dutch</td>\n",
       "      <td>2</td>\n",
       "      <td>validation</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1468</th>\n",
       "      <td>1275</td>\n",
       "      <td>22.0</td>\n",
       "      <td>male</td>\n",
       "      <td>dutch</td>\n",
       "      <td>1</td>\n",
       "      <td>validation</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1469</th>\n",
       "      <td>770</td>\n",
       "      <td>54.0</td>\n",
       "      <td>female</td>\n",
       "      <td>dutch</td>\n",
       "      <td>3</td>\n",
       "      <td>validation</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1470</th>\n",
       "      <td>2989</td>\n",
       "      <td>28.0</td>\n",
       "      <td>female</td>\n",
       "      <td>dutch</td>\n",
       "      <td>2</td>\n",
       "      <td>validation</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1471</th>\n",
       "      <td>1740</td>\n",
       "      <td>21.0</td>\n",
       "      <td>female</td>\n",
       "      <td>dutch</td>\n",
       "      <td>1</td>\n",
       "      <td>validation</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1472 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     url-id   age     sex   label age-group         set  n-f-n  s-f-o\n",
       "0       428  47.0    male  arabic         3       train   True      1\n",
       "1       421  21.0    male      uk         1       train   True      5\n",
       "2       420  26.0  female     usa         2       train  False      1\n",
       "3       419  21.0    male      uk         1       train   True      5\n",
       "4       412  21.0    male  french         1       train   True      5\n",
       "...     ...   ...     ...     ...       ...         ...    ...    ...\n",
       "1467   1484  25.0    male   dutch         2  validation  False      0\n",
       "1468   1275  22.0    male   dutch         1  validation  False      0\n",
       "1469    770  54.0  female   dutch         3  validation  False      0\n",
       "1470   2989  28.0  female   dutch         2  validation  False      0\n",
       "1471   1740  21.0  female   dutch         1  validation  False      0\n",
       "\n",
       "[1472 rows x 8 columns]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result_df_with_s_f_o = sampler_s_f_o(result_df_with_n_f_n)\n",
    "result_df_with_s_f_o\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "210"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result_df_with_s_f_o[(result_df_with_s_f_o[\"label\"]==\"french\") & (result_df_with_s_f_o[\"sex\"]==\"female\")][\"s-f-o\"].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Deciding how many times each sample is used in s-f-c (dataset B)\n",
    "\n",
    "def sampler_s_f_c(df):\n",
    "    # Initialize the s-f-c column with value 1 for each row\n",
    "    df[\"s-f-c\"] = 1\n",
    "\n",
    "    # Set s-f-c to 0 for testing and validation rows\n",
    "    df.loc[df[\"set\"] != \"train\", \"s-f-c\"] = 0\n",
    "\n",
    "    # Loop until the sum of s-f-c for both sexes with the same label is equal\n",
    "    while True:\n",
    "        # Initialize a boolean flag to track if any label has unequal sums\n",
    "        unequal_sum = False\n",
    "\n",
    "        # Loop through each label\n",
    "        for label in df[\"label\"].unique():\n",
    "            # Get the subsets of the DataFrame containing only rows with the current label in the training set, grouped by sex\n",
    "            subsets = [df[(df[\"label\"] == label) & (df[\"sex\"] == sex) & (df[\"set\"] == \"train\")] for sex in df[\"sex\"].unique()]\n",
    "\n",
    "            # Calculate the current sum of s-f-c for each sex in the label group\n",
    "            current_sums = [subset[\"s-f-c\"].sum() for subset in subsets]\n",
    "\n",
    "            # If the current sums are not equal\n",
    "            if current_sums[0] != current_sums[1]:\n",
    "                # Set the unequal_sum flag to True\n",
    "                unequal_sum = True\n",
    "\n",
    "                # Find the index of the subset with the smaller sum\n",
    "                smaller_subset_index = 0 if current_sums[0] < current_sums[1] else 1\n",
    "\n",
    "                # Randomly sample a row from the subset with the smaller sum\n",
    "                sampled_index = subsets[smaller_subset_index].sample(1).index\n",
    "\n",
    "                # Increment the s-f-c value for the sampled row\n",
    "                df.loc[sampled_index, \"s-f-c\"] += 1\n",
    "\n",
    "        # If none of the labels have unequal sums, break the loop\n",
    "        if not unequal_sum:\n",
    "            break\n",
    "\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>url-id</th>\n",
       "      <th>age</th>\n",
       "      <th>sex</th>\n",
       "      <th>label</th>\n",
       "      <th>age-group</th>\n",
       "      <th>set</th>\n",
       "      <th>n-f-n</th>\n",
       "      <th>s-f-o</th>\n",
       "      <th>s-f-c</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>428</td>\n",
       "      <td>47.0</td>\n",
       "      <td>male</td>\n",
       "      <td>arabic</td>\n",
       "      <td>3</td>\n",
       "      <td>train</td>\n",
       "      <td>True</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>421</td>\n",
       "      <td>21.0</td>\n",
       "      <td>male</td>\n",
       "      <td>uk</td>\n",
       "      <td>1</td>\n",
       "      <td>train</td>\n",
       "      <td>True</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>420</td>\n",
       "      <td>26.0</td>\n",
       "      <td>female</td>\n",
       "      <td>usa</td>\n",
       "      <td>2</td>\n",
       "      <td>train</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>419</td>\n",
       "      <td>21.0</td>\n",
       "      <td>male</td>\n",
       "      <td>uk</td>\n",
       "      <td>1</td>\n",
       "      <td>train</td>\n",
       "      <td>True</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>412</td>\n",
       "      <td>21.0</td>\n",
       "      <td>male</td>\n",
       "      <td>french</td>\n",
       "      <td>1</td>\n",
       "      <td>train</td>\n",
       "      <td>True</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1467</th>\n",
       "      <td>1484</td>\n",
       "      <td>25.0</td>\n",
       "      <td>male</td>\n",
       "      <td>dutch</td>\n",
       "      <td>2</td>\n",
       "      <td>validation</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1468</th>\n",
       "      <td>1275</td>\n",
       "      <td>22.0</td>\n",
       "      <td>male</td>\n",
       "      <td>dutch</td>\n",
       "      <td>1</td>\n",
       "      <td>validation</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1469</th>\n",
       "      <td>770</td>\n",
       "      <td>54.0</td>\n",
       "      <td>female</td>\n",
       "      <td>dutch</td>\n",
       "      <td>3</td>\n",
       "      <td>validation</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1470</th>\n",
       "      <td>2989</td>\n",
       "      <td>28.0</td>\n",
       "      <td>female</td>\n",
       "      <td>dutch</td>\n",
       "      <td>2</td>\n",
       "      <td>validation</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1471</th>\n",
       "      <td>1740</td>\n",
       "      <td>21.0</td>\n",
       "      <td>female</td>\n",
       "      <td>dutch</td>\n",
       "      <td>1</td>\n",
       "      <td>validation</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1472 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     url-id   age     sex   label age-group         set  n-f-n  s-f-o  s-f-c\n",
       "0       428  47.0    male  arabic         3       train   True      1      1\n",
       "1       421  21.0    male      uk         1       train   True      5      1\n",
       "2       420  26.0  female     usa         2       train  False      1      1\n",
       "3       419  21.0    male      uk         1       train   True      5      1\n",
       "4       412  21.0    male  french         1       train   True      5      1\n",
       "...     ...   ...     ...     ...       ...         ...    ...    ...    ...\n",
       "1467   1484  25.0    male   dutch         2  validation  False      0      0\n",
       "1468   1275  22.0    male   dutch         1  validation  False      0      0\n",
       "1469    770  54.0  female   dutch         3  validation  False      0      0\n",
       "1470   2989  28.0  female   dutch         2  validation  False      0      0\n",
       "1471   1740  21.0  female   dutch         1  validation  False      0      0\n",
       "\n",
       "[1472 rows x 9 columns]"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result_df_with_s_f_c = sampler_s_f_c(result_df_with_s_f_o)\n",
    "result_df_with_s_f_c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "26"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result_df_with_s_f_c[(result_df_with_s_f_c[\"label\"]==\"dutch\") & (result_df_with_s_f_c[\"sex\"]==\"female\")][\"s-f-c\"].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1516"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result_df_with_s_f_c[\"s-f-c\"].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# s-r-5o (dataset E)\n",
    "\n",
    "def sampler_s_r_5o(df):\n",
    "    # Initialize the s_r_5o column with value 1 for each row\n",
    "    df[\"s_r_5o\"] = 1\n",
    "\n",
    "    # Set s-f-o to 0 for testing and validation rows\n",
    "    df.loc[df[\"set\"] != \"train\", \"s_r_5o\"] = 0\n",
    "\n",
    "    # Define the target sum for each label - sex pair\n",
    "    target_sum = 1000\n",
    "\n",
    "    # Loop until the sum of s-f-o for each label - sex pair in the training set reaches the target sum\n",
    "    while True:\n",
    "        # Initialize a boolean flag to track if any pair is still below the target sum\n",
    "        below_target = False\n",
    "\n",
    "        # Loop through each label\n",
    "        for label in df[\"label\"].unique():\n",
    "            # Loop through each sex\n",
    "            for sex in df[\"sex\"].unique():\n",
    "                # Get a subset of the DataFrame containing only rows with the current label and sex in the training set\n",
    "                subset = df[(df[\"label\"] == label) & (df[\"sex\"] == sex) & (df[\"set\"] == \"train\")]\n",
    "\n",
    "                # Calculate the current sum of s-f-o for the label - sex pair\n",
    "                current_sum = subset[\"s_r_5o\"].sum()\n",
    "\n",
    "                # If the current sum is below the target sum\n",
    "                if current_sum < target_sum:\n",
    "                    # Set the below_target flag to True\n",
    "                    below_target = True\n",
    "\n",
    "                    # Randomly sample a row from the subset\n",
    "                    sampled_index = subset.sample(1).index\n",
    "\n",
    "                    # Increment the s-f-o value for the sampled row\n",
    "                    df.loc[sampled_index, \"s_r_5o\"] += 1\n",
    "\n",
    "        # If none of the label - sex pairs in the training set are below the target sum, break the loop\n",
    "        if not below_target:\n",
    "            break\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>url-id</th>\n",
       "      <th>age</th>\n",
       "      <th>sex</th>\n",
       "      <th>label</th>\n",
       "      <th>age-group</th>\n",
       "      <th>set</th>\n",
       "      <th>n-f-n</th>\n",
       "      <th>s-f-o</th>\n",
       "      <th>s-f-c</th>\n",
       "      <th>s_r_5o</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>428</td>\n",
       "      <td>47.0</td>\n",
       "      <td>male</td>\n",
       "      <td>arabic</td>\n",
       "      <td>3</td>\n",
       "      <td>train</td>\n",
       "      <td>True</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>421</td>\n",
       "      <td>21.0</td>\n",
       "      <td>male</td>\n",
       "      <td>uk</td>\n",
       "      <td>1</td>\n",
       "      <td>train</td>\n",
       "      <td>True</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>420</td>\n",
       "      <td>26.0</td>\n",
       "      <td>female</td>\n",
       "      <td>usa</td>\n",
       "      <td>2</td>\n",
       "      <td>train</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>419</td>\n",
       "      <td>21.0</td>\n",
       "      <td>male</td>\n",
       "      <td>uk</td>\n",
       "      <td>1</td>\n",
       "      <td>train</td>\n",
       "      <td>True</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>412</td>\n",
       "      <td>21.0</td>\n",
       "      <td>male</td>\n",
       "      <td>french</td>\n",
       "      <td>1</td>\n",
       "      <td>train</td>\n",
       "      <td>True</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1467</th>\n",
       "      <td>1484</td>\n",
       "      <td>25.0</td>\n",
       "      <td>male</td>\n",
       "      <td>dutch</td>\n",
       "      <td>2</td>\n",
       "      <td>validation</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1468</th>\n",
       "      <td>1275</td>\n",
       "      <td>22.0</td>\n",
       "      <td>male</td>\n",
       "      <td>dutch</td>\n",
       "      <td>1</td>\n",
       "      <td>validation</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1469</th>\n",
       "      <td>770</td>\n",
       "      <td>54.0</td>\n",
       "      <td>female</td>\n",
       "      <td>dutch</td>\n",
       "      <td>3</td>\n",
       "      <td>validation</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1470</th>\n",
       "      <td>2989</td>\n",
       "      <td>28.0</td>\n",
       "      <td>female</td>\n",
       "      <td>dutch</td>\n",
       "      <td>2</td>\n",
       "      <td>validation</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1471</th>\n",
       "      <td>1740</td>\n",
       "      <td>21.0</td>\n",
       "      <td>female</td>\n",
       "      <td>dutch</td>\n",
       "      <td>1</td>\n",
       "      <td>validation</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1472 rows × 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     url-id   age     sex   label age-group         set  n-f-n  s-f-o  s-f-c  \\\n",
       "0       428  47.0    male  arabic         3       train   True      1      1   \n",
       "1       421  21.0    male      uk         1       train   True      5      1   \n",
       "2       420  26.0  female     usa         2       train  False      1      1   \n",
       "3       419  21.0    male      uk         1       train   True      5      1   \n",
       "4       412  21.0    male  french         1       train   True      5      1   \n",
       "...     ...   ...     ...     ...       ...         ...    ...    ...    ...   \n",
       "1467   1484  25.0    male   dutch         2  validation  False      0      0   \n",
       "1468   1275  22.0    male   dutch         1  validation  False      0      0   \n",
       "1469    770  54.0  female   dutch         3  validation  False      0      0   \n",
       "1470   2989  28.0  female   dutch         2  validation  False      0      0   \n",
       "1471   1740  21.0  female   dutch         1  validation  False      0      0   \n",
       "\n",
       "      s_r_5o  \n",
       "0         14  \n",
       "1         22  \n",
       "2          5  \n",
       "3         28  \n",
       "4         31  \n",
       "...      ...  \n",
       "1467       0  \n",
       "1468       0  \n",
       "1469       0  \n",
       "1470       0  \n",
       "1471       0  \n",
       "\n",
       "[1472 rows x 10 columns]"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result_df_with_s_r_5o = sampler_s_r_5o(result_df_with_s_f_c)\n",
    "result_df_with_s_r_5o"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20000"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result_df_with_s_f_c[\"s_r_5o\"].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This dataset was not used in the thesis\n",
    "\n",
    "def sampler_s_r_10c(df):\n",
    "    # Initialize the s-r-5c column with value 1 for each row\n",
    "    df[\"s-r-10c\"] = 1\n",
    "\n",
    "    # Set s-r-5c to 0 for testing and validation rows\n",
    "    df.loc[df[\"set\"] != \"train\", \"s-r-10c\"] = 0\n",
    "\n",
    "    # Loop until the sum of s-r-5c for both sexes with the same label is five times the count of the larger sex in the label\n",
    "    while True:\n",
    "        # Initialize a boolean flag to track if any label has not reached the target sum\n",
    "        below_target = False\n",
    "\n",
    "        # Loop through each label\n",
    "        for label in df[\"label\"].unique():\n",
    "            # Get the subsets of the DataFrame containing only rows with the current label in the training set, grouped by sex\n",
    "            subsets = [df[(df[\"label\"] == label) & (df[\"sex\"] == sex) & (df[\"set\"] == \"train\")] for sex in df[\"sex\"].unique()]\n",
    "\n",
    "            # Calculate the current sum of s-r-5c for each sex in the label group\n",
    "            current_sums = [subset[\"s-r-10c\"].sum() for subset in subsets]\n",
    "\n",
    "            # Calculate the target sum as five times the count of the larger sex in the label\n",
    "            target_sum = 10 * max(len(subsets[0]), len(subsets[1]))\n",
    "\n",
    "            # Check if any of the sums are below the target sum\n",
    "            if any(current_sum < target_sum for current_sum in current_sums):\n",
    "                # Set the below_target flag to True\n",
    "                below_target = True\n",
    "\n",
    "                # Find the index of the subset with the smaller sum\n",
    "                smaller_subset_index = 0 if current_sums[0] < current_sums[1] else 1\n",
    "\n",
    "                # Randomly sample a row from the subset with the smaller sum\n",
    "                sampled_index = subsets[smaller_subset_index].sample(1).index\n",
    "\n",
    "                # Increment the s-r-5c value for the sampled row\n",
    "                df.loc[sampled_index, \"s-r-10c\"] += 1\n",
    "\n",
    "        # If none of the labels have sums below the target sum, break the loop\n",
    "        if not below_target:\n",
    "            break\n",
    "\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>url-id</th>\n",
       "      <th>age</th>\n",
       "      <th>sex</th>\n",
       "      <th>label</th>\n",
       "      <th>age-group</th>\n",
       "      <th>set</th>\n",
       "      <th>n-f-n</th>\n",
       "      <th>s-f-o</th>\n",
       "      <th>s-f-c</th>\n",
       "      <th>s_r_5o</th>\n",
       "      <th>s-r-5c</th>\n",
       "      <th>s-r-10c</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>428</td>\n",
       "      <td>47.0</td>\n",
       "      <td>male</td>\n",
       "      <td>arabic</td>\n",
       "      <td>3</td>\n",
       "      <td>train</td>\n",
       "      <td>True</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>14</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>421</td>\n",
       "      <td>21.0</td>\n",
       "      <td>male</td>\n",
       "      <td>uk</td>\n",
       "      <td>1</td>\n",
       "      <td>train</td>\n",
       "      <td>True</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>22</td>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>420</td>\n",
       "      <td>26.0</td>\n",
       "      <td>female</td>\n",
       "      <td>usa</td>\n",
       "      <td>2</td>\n",
       "      <td>train</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>419</td>\n",
       "      <td>21.0</td>\n",
       "      <td>male</td>\n",
       "      <td>uk</td>\n",
       "      <td>1</td>\n",
       "      <td>train</td>\n",
       "      <td>True</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>28</td>\n",
       "      <td>5</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>412</td>\n",
       "      <td>21.0</td>\n",
       "      <td>male</td>\n",
       "      <td>french</td>\n",
       "      <td>1</td>\n",
       "      <td>train</td>\n",
       "      <td>True</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>31</td>\n",
       "      <td>9</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1467</th>\n",
       "      <td>1484</td>\n",
       "      <td>25.0</td>\n",
       "      <td>male</td>\n",
       "      <td>dutch</td>\n",
       "      <td>2</td>\n",
       "      <td>validation</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1468</th>\n",
       "      <td>1275</td>\n",
       "      <td>22.0</td>\n",
       "      <td>male</td>\n",
       "      <td>dutch</td>\n",
       "      <td>1</td>\n",
       "      <td>validation</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1469</th>\n",
       "      <td>770</td>\n",
       "      <td>54.0</td>\n",
       "      <td>female</td>\n",
       "      <td>dutch</td>\n",
       "      <td>3</td>\n",
       "      <td>validation</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1470</th>\n",
       "      <td>2989</td>\n",
       "      <td>28.0</td>\n",
       "      <td>female</td>\n",
       "      <td>dutch</td>\n",
       "      <td>2</td>\n",
       "      <td>validation</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1471</th>\n",
       "      <td>1740</td>\n",
       "      <td>21.0</td>\n",
       "      <td>female</td>\n",
       "      <td>dutch</td>\n",
       "      <td>1</td>\n",
       "      <td>validation</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1472 rows × 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     url-id   age     sex   label age-group         set  n-f-n  s-f-o  s-f-c  \\\n",
       "0       428  47.0    male  arabic         3       train   True      1      1   \n",
       "1       421  21.0    male      uk         1       train   True      5      1   \n",
       "2       420  26.0  female     usa         2       train  False      1      1   \n",
       "3       419  21.0    male      uk         1       train   True      5      1   \n",
       "4       412  21.0    male  french         1       train   True      5      1   \n",
       "...     ...   ...     ...     ...       ...         ...    ...    ...    ...   \n",
       "1467   1484  25.0    male   dutch         2  validation  False      0      0   \n",
       "1468   1275  22.0    male   dutch         1  validation  False      0      0   \n",
       "1469    770  54.0  female   dutch         3  validation  False      0      0   \n",
       "1470   2989  28.0  female   dutch         2  validation  False      0      0   \n",
       "1471   1740  21.0  female   dutch         1  validation  False      0      0   \n",
       "\n",
       "      s_r_5o  s-r-5c  s-r-10c  \n",
       "0         14       3       10  \n",
       "1         22       2        7  \n",
       "2          5       6        6  \n",
       "3         28       5       14  \n",
       "4         31       9       13  \n",
       "...      ...     ...      ...  \n",
       "1467       0       0        0  \n",
       "1468       0       0        0  \n",
       "1469       0       0        0  \n",
       "1470       0       0        0  \n",
       "1471       0       0        0  \n",
       "\n",
       "[1472 rows x 12 columns]"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result_df_with_s_r_10c = sampler_s_r_10c(result_df_with_s_r_5c)\n",
    "result_df_with_s_r_10c\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_df_with_s_r_10c[\"n-f-n\"] = result_df_with_s_r_10c[\"n-f-n\"].astype(int)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_df_with_s_r_10c = result_df_with_s_r_10c.rename(columns={\"s_r_5o\": \"s-r-5o\"})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>url-id</th>\n",
       "      <th>age</th>\n",
       "      <th>sex</th>\n",
       "      <th>label</th>\n",
       "      <th>age-group</th>\n",
       "      <th>set</th>\n",
       "      <th>n-f-n</th>\n",
       "      <th>s-f-o</th>\n",
       "      <th>s-f-c</th>\n",
       "      <th>s-r-5o</th>\n",
       "      <th>s-r-5c</th>\n",
       "      <th>s-r-10c</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>428</td>\n",
       "      <td>47.0</td>\n",
       "      <td>male</td>\n",
       "      <td>arabic</td>\n",
       "      <td>3</td>\n",
       "      <td>train</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>14</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>421</td>\n",
       "      <td>21.0</td>\n",
       "      <td>male</td>\n",
       "      <td>uk</td>\n",
       "      <td>1</td>\n",
       "      <td>train</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>22</td>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>420</td>\n",
       "      <td>26.0</td>\n",
       "      <td>female</td>\n",
       "      <td>usa</td>\n",
       "      <td>2</td>\n",
       "      <td>train</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>419</td>\n",
       "      <td>21.0</td>\n",
       "      <td>male</td>\n",
       "      <td>uk</td>\n",
       "      <td>1</td>\n",
       "      <td>train</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>28</td>\n",
       "      <td>5</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>412</td>\n",
       "      <td>21.0</td>\n",
       "      <td>male</td>\n",
       "      <td>french</td>\n",
       "      <td>1</td>\n",
       "      <td>train</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>31</td>\n",
       "      <td>9</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1467</th>\n",
       "      <td>1484</td>\n",
       "      <td>25.0</td>\n",
       "      <td>male</td>\n",
       "      <td>dutch</td>\n",
       "      <td>2</td>\n",
       "      <td>validation</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1468</th>\n",
       "      <td>1275</td>\n",
       "      <td>22.0</td>\n",
       "      <td>male</td>\n",
       "      <td>dutch</td>\n",
       "      <td>1</td>\n",
       "      <td>validation</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1469</th>\n",
       "      <td>770</td>\n",
       "      <td>54.0</td>\n",
       "      <td>female</td>\n",
       "      <td>dutch</td>\n",
       "      <td>3</td>\n",
       "      <td>validation</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1470</th>\n",
       "      <td>2989</td>\n",
       "      <td>28.0</td>\n",
       "      <td>female</td>\n",
       "      <td>dutch</td>\n",
       "      <td>2</td>\n",
       "      <td>validation</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1471</th>\n",
       "      <td>1740</td>\n",
       "      <td>21.0</td>\n",
       "      <td>female</td>\n",
       "      <td>dutch</td>\n",
       "      <td>1</td>\n",
       "      <td>validation</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1472 rows × 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     url-id   age     sex   label age-group         set  n-f-n  s-f-o  s-f-c  \\\n",
       "0       428  47.0    male  arabic         3       train      1      1      1   \n",
       "1       421  21.0    male      uk         1       train      1      5      1   \n",
       "2       420  26.0  female     usa         2       train      0      1      1   \n",
       "3       419  21.0    male      uk         1       train      1      5      1   \n",
       "4       412  21.0    male  french         1       train      1      5      1   \n",
       "...     ...   ...     ...     ...       ...         ...    ...    ...    ...   \n",
       "1467   1484  25.0    male   dutch         2  validation      1      1      1   \n",
       "1468   1275  22.0    male   dutch         1  validation      1      1      1   \n",
       "1469    770  54.0  female   dutch         3  validation      1      1      1   \n",
       "1470   2989  28.0  female   dutch         2  validation      1      1      1   \n",
       "1471   1740  21.0  female   dutch         1  validation      1      1      1   \n",
       "\n",
       "      s-r-5o  s-r-5c  s-r-10c  \n",
       "0         14       3       10  \n",
       "1         22       2        7  \n",
       "2          5       6        6  \n",
       "3         28       5       14  \n",
       "4         31       9       13  \n",
       "...      ...     ...      ...  \n",
       "1467       5       5        5  \n",
       "1468       5       5        5  \n",
       "1469       5       5        5  \n",
       "1470       5       5        5  \n",
       "1471       5       5        5  \n",
       "\n",
       "[1472 rows x 12 columns]"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result_df_with_s_r_10c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is defining how many times the testing and validation set speakers will be sampled\n",
    "# Generally once, except for the datasets that take random samples, there it is defined this way so that the test sets also contain multiple different random samples\n",
    "\n",
    "result_df_with_s_r_10c.loc[result_df_with_s_r_10c[\"set\"] == \"validation\", \"n-f-n\"] = 1\n",
    "result_df_with_s_r_10c.loc[result_df_with_s_r_10c[\"set\"] == \"test\", \"n-f-n\"] = 1\n",
    "result_df_with_s_r_10c.loc[result_df_with_s_r_10c[\"set\"] == \"validation\", \"s-f-o\"] = 1\n",
    "result_df_with_s_r_10c.loc[result_df_with_s_r_10c[\"set\"] == \"test\", \"s-f-o\"] = 1\n",
    "result_df_with_s_r_10c.loc[result_df_with_s_r_10c[\"set\"] == \"validation\", \"s-f-c\"] = 1\n",
    "result_df_with_s_r_10c.loc[result_df_with_s_r_10c[\"set\"] == \"test\", \"s-f-c\"] = 1\n",
    "result_df_with_s_r_10c.loc[result_df_with_s_r_10c[\"set\"] == \"validation\", \"s-r-5o\"] = 5\n",
    "result_df_with_s_r_10c.loc[result_df_with_s_r_10c[\"set\"] == \"test\", \"s-r-5o\"] = 5\n",
    "result_df_with_s_r_10c.loc[result_df_with_s_r_10c[\"set\"] == \"validation\", \"s-r-5c\"] = 5\n",
    "result_df_with_s_r_10c.loc[result_df_with_s_r_10c[\"set\"] == \"test\", \"s-r-5c\"] = 5\n",
    "result_df_with_s_r_10c.loc[result_df_with_s_r_10c[\"set\"] == \"validation\", \"s-r-10c\"] = 5\n",
    "result_df_with_s_r_10c.loc[result_df_with_s_r_10c[\"set\"] == \"test\", \"s-r-10c\"] = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import librosa\n",
    "import numpy as np\n",
    "import soundfile as sf\n",
    "\n",
    "# This is the function that actually creates the audio datasets\n",
    "# It samples according to the instructions of the dataframe created above\n",
    "\n",
    "def organize_audio_files(df, column, src_dir, target_duration=10):\n",
    "    # Create the main output folder if it doesn't exist\n",
    "    if not os.path.exists(column):\n",
    "        os.makedirs(column)\n",
    "\n",
    "    # Loop through each unique set value (train, test, validation)\n",
    "    for set_value in df[\"set\"].unique():\n",
    "        # Create the set folder if it doesn't exist\n",
    "        set_folder = os.path.join(column, set_value)\n",
    "        if not os.path.exists(set_folder):\n",
    "            os.makedirs(set_folder)\n",
    "\n",
    "        # Loop through each unique label value\n",
    "        for label in df[\"label\"].unique():\n",
    "            # Create the label folder if it doesn't exist\n",
    "            label_folder = os.path.join(set_folder, label)\n",
    "            if not os.path.exists(label_folder):\n",
    "                os.makedirs(label_folder)\n",
    "\n",
    "            # Filter the DataFrame based on the current set and label values\n",
    "            filtered_df = df[(df[\"set\"] == set_value) & (df[\"label\"] == label)]\n",
    "\n",
    "            # Loop through each row in the filtered DataFrame\n",
    "            for _, row in filtered_df.iterrows():\n",
    "                # Calculate the number of copies needed\n",
    "                num_copies = row[column]\n",
    "\n",
    "                # Load the audio file using librosa\n",
    "                src_file = os.path.join(src_dir, f\"{row['url-id']}.mp3\")\n",
    "                audio, sr = librosa.load(src_file, sr=None)\n",
    "\n",
    "                # Calculate target length in samples\n",
    "                target_length = target_duration * sr\n",
    "\n",
    "                # Crop or pad the audio to the target length\n",
    "                if len(audio) >= target_length:\n",
    "                    audio = audio[:target_length]\n",
    "                else:\n",
    "                    audio = np.pad(audio, (0, target_length - len(audio)))\n",
    "\n",
    "                # Create the required number of copies for the current audio file\n",
    "                for i in range(num_copies):\n",
    "                    dst_file = os.path.join(label_folder, f\"{row['url-id']}_{i}.wav\")\n",
    "\n",
    "                    # Save the processed audio as a WAV file\n",
    "                    sf.write(dst_file, audio, sr)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "organize_audio_files(result_df_with_s_r_10c, \"n-f-n\", r\"D:\\Data Science and Entrepreneurship MSc\\Thesis\\Data\\SAA\\all_mp3s\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "organize_audio_files(result_df_with_s_r_10c, \"s-f-o\", r\"D:\\Data Science and Entrepreneurship MSc\\Thesis\\Data\\SAA\\all_mp3s\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "organize_audio_files(result_df_with_s_r_10c, \"s-f-c\", r\"D:\\Data Science and Entrepreneurship MSc\\Thesis\\Data\\SAA\\all_mp3s\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import librosa\n",
    "import numpy as np\n",
    "import soundfile as sf\n",
    "\n",
    "# Another version of the above function that takes random samples rather than the first part of the audio\n",
    "\n",
    "def organize_audio_files(df, column, src_dir, target_duration=10, random_seed=42):\n",
    "    np.random.seed(random_seed)\n",
    "\n",
    "    # Create the main output folder if it doesn't exist\n",
    "    if not os.path.exists(column):\n",
    "        os.makedirs(column)\n",
    "\n",
    "    # Loop through each unique set value (train, test, validation)\n",
    "    for set_value in df[\"set\"].unique():\n",
    "        # Create the set folder if it doesn't exist\n",
    "        set_folder = os.path.join(column, set_value)\n",
    "        if not os.path.exists(set_folder):\n",
    "            os.makedirs(set_folder)\n",
    "\n",
    "        # Loop through each unique label value\n",
    "        for label in df[\"label\"].unique():\n",
    "            # Create the label folder if it doesn't exist\n",
    "            label_folder = os.path.join(set_folder, label)\n",
    "            if not os.path.exists(label_folder):\n",
    "                os.makedirs(label_folder)\n",
    "\n",
    "            # Filter the DataFrame based on the current set and label values\n",
    "            filtered_df = df[(df[\"set\"] == set_value) & (df[\"label\"] == label)]\n",
    "\n",
    "            # Loop through each row in the filtered DataFrame\n",
    "            for _, row in filtered_df.iterrows():\n",
    "                # Calculate the number of copies needed\n",
    "                num_copies = row[column]\n",
    "\n",
    "                # Load the audio file using librosa\n",
    "                src_file = os.path.join(src_dir, f\"{row['url-id']}.mp3\")\n",
    "                audio, sr = librosa.load(src_file, sr=None)\n",
    "\n",
    "                # Calculate target length in samples\n",
    "                target_length = target_duration * sr\n",
    "\n",
    "                # Loop for each copy of the current audio file\n",
    "                for i in range(num_copies):\n",
    "                    # Check if the audio length is greater than or equal to the target length\n",
    "                    if len(audio) >= target_length:\n",
    "                        # Choose a random start position for the 10-second sample\n",
    "                        start = np.random.randint(0, len(audio) - target_length + 1)\n",
    "                        end = start + target_length\n",
    "                        cropped_audio = audio[start:end]\n",
    "                    else:\n",
    "                        cropped_audio = np.pad(audio, (0, target_length - len(audio)))\n",
    "\n",
    "                    dst_file = os.path.join(label_folder, f\"{row['url-id']}_{i}.wav\")\n",
    "\n",
    "                    # Save the processed audio as a WAV file\n",
    "                    sf.write(dst_file, cropped_audio, sr)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "organize_audio_files(result_df_with_s_r_10c, \"s-r-5o\", r\"D:\\Data Science and Entrepreneurship MSc\\Thesis\\Data\\SAA\\all_mp3s\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "organize_audio_files(result_df_with_s_r_10c, \"s-r-5c\", r\"D:\\Data Science and Entrepreneurship MSc\\Thesis\\Data\\SAA\\all_mp3s\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "organize_audio_files(result_df_with_s_r_10c, \"s-r-10c\", r\"D:\\Data Science and Entrepreneurship MSc\\Thesis\\Data\\SAA\\all_mp3s\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Upload datasets to Hugging Face Hub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'11.0.0'"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pyarrow\n",
    "pyarrow.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datasets\n",
    "from datasets import load_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Resolving data files: 100%|██████████| 784/784 [00:00<00:00, 193397.30it/s]\n",
      "Resolving data files: 100%|██████████| 60/60 [00:00<00:00, 60090.32it/s]\n",
      "Resolving data files: 100%|██████████| 60/60 [00:00<00:00, 60190.92it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading and preparing dataset audiofolder/n-f-n to C:/Users/Rita/.cache/huggingface/datasets/audiofolder/n-f-n-336de0eaea3d8d91/0.0.0/6cbdd16f8688354c63b4e2a36e1585d05de285023ee6443ffd71c4182055c0fc...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading data files: 100%|██████████| 784/784 [00:00<00:00, 8426.03it/s]\n",
      "Downloading data files: 0it [00:00, ?it/s]\n",
      "Extracting data files: 0it [00:00, ?it/s]\n",
      "Downloading data files: 100%|██████████| 60/60 [00:00<00:00, 7507.48it/s]\n",
      "Downloading data files: 0it [00:00, ?it/s]\n",
      "Extracting data files: 0it [00:00, ?it/s]\n",
      "Downloading data files: 100%|██████████| 60/60 [00:00<00:00, 4999.67it/s]\n",
      "Downloading data files: 0it [00:00, ?it/s]\n",
      "Extracting data files: 0it [00:00, ?it/s]\n",
      "                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset audiofolder downloaded and prepared to C:/Users/Rita/.cache/huggingface/datasets/audiofolder/n-f-n-336de0eaea3d8d91/0.0.0/6cbdd16f8688354c63b4e2a36e1585d05de285023ee6443ffd71c4182055c0fc. Subsequent calls will reuse this data.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3/3 [00:00<00:00, 57.69it/s]\n"
     ]
    }
   ],
   "source": [
    "dataset = load_dataset(\"n-f-n\", name='SAA_n-f-n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Pushing split train to the Hub.\n",
      "Creating parquet from Arrow format: 100%|██████████| 1/1 [00:01<00:00,  1.31s/ba]\n",
      "Upload 1 LFS files: 100%|██████████| 1/1 [01:50<00:00, 110.47s/it]\n",
      "Creating parquet from Arrow format: 100%|██████████| 1/1 [00:01<00:00,  1.33s/ba].23s/it]\n",
      "Upload 1 LFS files: 100%|██████████| 1/1 [01:29<00:00, 89.52s/it]\n",
      "Pushing dataset shards to the dataset hub: 100%|██████████| 2/2 [03:31<00:00, 105.54s/it]\n",
      "Pushing split test to the Hub.\n",
      "Creating parquet from Arrow format: 100%|██████████| 1/1 [00:00<00:00,  4.58ba/s]\n",
      "Upload 1 LFS files: 100%|██████████| 1/1 [00:14<00:00, 14.14s/it]\n",
      "Pushing dataset shards to the dataset hub: 100%|██████████| 1/1 [00:15<00:00, 15.24s/it]\n",
      "Pushing split validation to the Hub.\n",
      "Creating parquet from Arrow format: 100%|██████████| 1/1 [00:00<00:00,  4.33ba/s]\n",
      "Upload 1 LFS files: 100%|██████████| 1/1 [00:15<00:00, 15.37s/it]\n",
      "Pushing dataset shards to the dataset hub: 100%|██████████| 1/1 [00:16<00:00, 16.50s/it]\n"
     ]
    }
   ],
   "source": [
    "dataset.push_to_hub(\"reralle/n-f-n\", private=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Resolving data files: 100%|██████████| 4200/4200 [00:00<00:00, 8741.72it/s] \n",
      "Resolving data files: 100%|██████████| 60/60 [00:00<00:00, 57548.19it/s]\n",
      "Resolving data files: 100%|██████████| 60/60 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading and preparing dataset audiofolder/s-f-o to C:/Users/Rita/.cache/huggingface/datasets/audiofolder/s-f-o-22fb25859134090f/0.0.0/6cbdd16f8688354c63b4e2a36e1585d05de285023ee6443ffd71c4182055c0fc...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading data files: 100%|██████████| 4200/4200 [00:00<00:00, 9900.81it/s] \n",
      "Downloading data files: 0it [00:00, ?it/s]\n",
      "Extracting data files: 0it [00:00, ?it/s]\n",
      "Downloading data files: 100%|██████████| 60/60 [00:00<00:00, 9936.36it/s]\n",
      "Downloading data files: 0it [00:00, ?it/s]\n",
      "Extracting data files: 0it [00:00, ?it/s]\n",
      "Downloading data files: 100%|██████████| 60/60 [00:00<00:00, 7510.62it/s]\n",
      "Downloading data files: 0it [00:00, ?it/s]\n",
      "Extracting data files: 0it [00:00, ?it/s]\n",
      "                                                                 \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset audiofolder downloaded and prepared to C:/Users/Rita/.cache/huggingface/datasets/audiofolder/s-f-o-22fb25859134090f/0.0.0/6cbdd16f8688354c63b4e2a36e1585d05de285023ee6443ffd71c4182055c0fc. Subsequent calls will reuse this data.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3/3 [00:00<00:00, 33.71it/s]\n",
      "Pushing split train to the Hub.\n",
      "Creating parquet from Arrow format: 100%|██████████| 1/1 [00:00<00:00,  1.46ba/s]\n",
      "Upload 1 LFS files: 100%|██████████| 1/1 [02:20<00:00, 140.56s/it]\n",
      "Creating parquet from Arrow format: 100%|██████████| 1/1 [00:00<00:00,  2.81ba/s].35s/it]\n",
      "Upload 1 LFS files: 100%|██████████| 1/1 [00:19<00:00, 19.40s/it]\n",
      "Creating parquet from Arrow format: 100%|██████████| 1/1 [00:00<00:00,  2.43ba/s]02s/it] \n",
      "Upload 1 LFS files: 100%|██████████| 1/1 [00:48<00:00, 48.74s/it]\n",
      "Creating parquet from Arrow format: 100%|██████████| 1/1 [00:00<00:00,  1.64ba/s]74s/it]\n",
      "Upload 1 LFS files: 100%|██████████| 1/1 [00:57<00:00, 57.33s/it]\n",
      "Creating parquet from Arrow format: 100%|██████████| 1/1 [00:00<00:00,  3.08ba/s]43s/it]\n",
      "Upload 1 LFS files: 100%|██████████| 1/1 [00:30<00:00, 30.69s/it]\n",
      "Creating parquet from Arrow format: 100%|██████████| 1/1 [00:00<00:00,  1.65ba/s]08s/it]\n",
      "Upload 1 LFS files: 100%|██████████| 1/1 [01:13<00:00, 73.39s/it]\n",
      "Creating parquet from Arrow format: 100%|██████████| 1/1 [00:00<00:00,  1.91ba/s]81s/it]\n",
      "Upload 1 LFS files: 100%|██████████| 1/1 [00:49<00:00, 49.04s/it]\n",
      "Creating parquet from Arrow format: 100%|██████████| 1/1 [00:01<00:00,  1.33s/ba]21s/it]\n",
      "Upload 1 LFS files: 100%|██████████| 1/1 [02:59<00:00, 179.74s/it]\n",
      "Pushing dataset shards to the dataset hub: 100%|██████████| 8/8 [10:50<00:00, 81.36s/it] \n",
      "Pushing split test to the Hub.\n",
      "Creating parquet from Arrow format: 100%|██████████| 1/1 [00:00<00:00,  5.10ba/s]\n",
      "Upload 1 LFS files: 100%|██████████| 1/1 [00:41<00:00, 41.19s/it]\n",
      "Pushing dataset shards to the dataset hub: 100%|██████████| 1/1 [00:42<00:00, 42.28s/it]\n",
      "Pushing split validation to the Hub.\n",
      "Creating parquet from Arrow format: 100%|██████████| 1/1 [00:00<00:00,  5.26ba/s]\n",
      "Upload 1 LFS files: 100%|██████████| 1/1 [00:16<00:00, 16.77s/it]\n",
      "Pushing dataset shards to the dataset hub: 100%|██████████| 1/1 [00:17<00:00, 17.75s/it]\n"
     ]
    }
   ],
   "source": [
    "dataset = load_dataset(\"s-f-o\", name='SAA_s-f-o')\n",
    "dataset.push_to_hub(\"reralle/s-f-o\", private=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Resolving data files: 100%|██████████| 1516/1516 [00:00<00:00, 16478.09it/s]\n",
      "Resolving data files: 100%|██████████| 60/60 [00:00<00:00, 60176.53it/s]\n",
      "Resolving data files: 100%|██████████| 60/60 [00:00<00:00, 61802.12it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading and preparing dataset audiofolder/s-f-c to C:/Users/Rita/.cache/huggingface/datasets/audiofolder/s-f-c-5859f3ec5242cb1f/0.0.0/6cbdd16f8688354c63b4e2a36e1585d05de285023ee6443ffd71c4182055c0fc...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading data files: 100%|██████████| 1516/1516 [00:00<00:00, 9298.99it/s]\n",
      "Downloading data files: 0it [00:00, ?it/s]\n",
      "Extracting data files: 0it [00:00, ?it/s]\n",
      "Downloading data files: 100%|██████████| 60/60 [00:00<00:00, 9936.36it/s]\n",
      "Downloading data files: 0it [00:00, ?it/s]\n",
      "Extracting data files: 0it [00:00, ?it/s]\n",
      "Downloading data files: 100%|██████████| 60/60 [00:00<00:00, 8536.86it/s]\n",
      "Downloading data files: 0it [00:00, ?it/s]\n",
      "Extracting data files: 0it [00:00, ?it/s]\n",
      "                                                                 \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset audiofolder downloaded and prepared to C:/Users/Rita/.cache/huggingface/datasets/audiofolder/s-f-c-5859f3ec5242cb1f/0.0.0/6cbdd16f8688354c63b4e2a36e1585d05de285023ee6443ffd71c4182055c0fc. Subsequent calls will reuse this data.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3/3 [00:00<00:00, 52.41it/s]\n",
      "Pushing split train to the Hub.\n",
      "Creating parquet from Arrow format: 100%|██████████| 1/1 [00:01<00:00,  1.26s/ba]\n",
      "Upload 1 LFS files: 100%|██████████| 1/1 [01:57<00:00, 117.44s/it]\n",
      "Creating parquet from Arrow format: 100%|██████████| 1/1 [00:01<00:00,  1.50s/ba].11s/it]\n",
      "Upload 1 LFS files: 100%|██████████| 1/1 [01:50<00:00, 110.41s/it]\n",
      "Creating parquet from Arrow format: 100%|██████████| 1/1 [00:01<00:00,  1.57s/ba].23s/it]\n",
      "Upload 1 LFS files: 100%|██████████| 1/1 [02:08<00:00, 128.43s/it]\n",
      "Pushing dataset shards to the dataset hub: 100%|██████████| 3/3 [06:14<00:00, 124.99s/it]\n",
      "Pushing split test to the Hub.\n",
      "Creating parquet from Arrow format: 100%|██████████| 1/1 [00:00<00:00,  5.35ba/s]\n",
      "Upload 1 LFS files: 100%|██████████| 1/1 [00:17<00:00, 17.18s/it]\n",
      "Pushing dataset shards to the dataset hub: 100%|██████████| 1/1 [00:18<00:00, 18.21s/it]\n",
      "Pushing split validation to the Hub.\n",
      "Creating parquet from Arrow format: 100%|██████████| 1/1 [00:00<00:00,  5.10ba/s]\n",
      "Upload 1 LFS files: 100%|██████████| 1/1 [00:18<00:00, 18.60s/it]\n",
      "Pushing dataset shards to the dataset hub: 100%|██████████| 1/1 [00:19<00:00, 19.60s/it]\n"
     ]
    }
   ],
   "source": [
    "dataset = load_dataset(\"s-f-c\", name='SAA_s-f-c')\n",
    "dataset.push_to_hub(\"reralle/s-f-c\", private=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Resolving data files: 100%|██████████| 20000/20000 [00:01<00:00, 12357.54it/s]\n",
      "Resolving data files: 100%|██████████| 300/300 [00:00<00:00, 299735.87it/s]\n",
      "Resolving data files: 100%|██████████| 300/300 [00:00<00:00, 298739.60it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading and preparing dataset audiofolder/s-r-5o to C:/Users/Rita/.cache/huggingface/datasets/audiofolder/s-r-5o-1663b601c9454370/0.0.0/6cbdd16f8688354c63b4e2a36e1585d05de285023ee6443ffd71c4182055c0fc...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading data files: 100%|██████████| 20000/20000 [00:02<00:00, 8254.46it/s]\n",
      "Downloading data files: 0it [00:00, ?it/s]\n",
      "Extracting data files: 0it [00:00, ?it/s]\n",
      "Downloading data files: 100%|██████████| 300/300 [00:00<00:00, 7892.09it/s]\n",
      "Downloading data files: 0it [00:00, ?it/s]\n",
      "Extracting data files: 0it [00:00, ?it/s]\n",
      "Downloading data files: 100%|██████████| 300/300 [00:00<00:00, 5657.10it/s]\n",
      "Downloading data files: 0it [00:00, ?it/s]\n",
      "Extracting data files: 0it [00:00, ?it/s]\n",
      "                                                                  \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset audiofolder downloaded and prepared to C:/Users/Rita/.cache/huggingface/datasets/audiofolder/s-r-5o-1663b601c9454370/0.0.0/6cbdd16f8688354c63b4e2a36e1585d05de285023ee6443ffd71c4182055c0fc. Subsequent calls will reuse this data.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3/3 [00:00<00:00, 11.91it/s]\n",
      "Pushing split train to the Hub.\n",
      "Creating parquet from Arrow format: 100%|██████████| 1/1 [00:01<00:00,  1.95s/ba]\n",
      "Upload 1 LFS files: 100%|██████████| 1/1 [02:01<00:00, 121.97s/it]\n",
      "Creating parquet from Arrow format: 100%|██████████| 1/1 [00:01<00:00,  1.95s/ba]125.77s/it]\n",
      "Upload 1 LFS files: 100%|██████████| 1/1 [01:59<00:00, 119.42s/it]\n",
      "Creating parquet from Arrow format: 100%|██████████| 1/1 [00:02<00:00,  2.15s/ba]128.19s/it]\n",
      "Upload 1 LFS files: 100%|██████████| 1/1 [02:11<00:00, 131.09s/it]\n",
      "Creating parquet from Arrow format: 100%|██████████| 1/1 [00:01<00:00,  1.58s/ba]134.22s/it]\n",
      "Upload 1 LFS files: 100%|██████████| 1/1 [01:45<00:00, 105.37s/it]\n",
      "Creating parquet from Arrow format: 100%|██████████| 1/1 [00:02<00:00,  2.04s/ba]126.86s/it]\n",
      "Upload 1 LFS files: 100%|██████████| 1/1 [02:21<00:00, 141.34s/it]\n",
      "Creating parquet from Arrow format: 100%|██████████| 1/1 [00:01<00:00,  1.99s/ba]135.94s/it]\n",
      "Upload 1 LFS files: 100%|██████████| 1/1 [02:04<00:00, 124.99s/it]\n",
      "Creating parquet from Arrow format: 100%|██████████| 1/1 [00:02<00:00,  2.02s/ba]135.72s/it]\n",
      "Upload 1 LFS files: 100%|██████████| 1/1 [02:06<00:00, 126.29s/it]\n",
      "Creating parquet from Arrow format: 100%|██████████| 1/1 [00:01<00:00,  1.98s/ba]135.99s/it]\n",
      "Upload 1 LFS files: 100%|██████████| 1/1 [02:09<00:00, 129.23s/it]\n",
      "Creating parquet from Arrow format: 100%|██████████| 1/1 [00:01<00:00,  1.97s/ba]137.21s/it]\n",
      "Upload 1 LFS files: 100%|██████████| 1/1 [02:10<00:00, 130.97s/it]\n",
      "Creating parquet from Arrow format: 100%|██████████| 1/1 [00:01<00:00,  1.42s/ba]138.63s/it]\n",
      "Upload 1 LFS files: 100%|██████████| 1/1 [01:40<00:00, 100.25s/it]\n",
      "Creating parquet from Arrow format: 100%|██████████| 1/1 [00:01<00:00,  1.98s/ba]29.73s/it] \n",
      "Upload 1 LFS files: 100%|██████████| 1/1 [02:53<00:00, 173.70s/it]\n",
      "Creating parquet from Arrow format: 100%|██████████| 1/1 [00:02<00:00,  2.08s/ba] 146.32s/it]\n",
      "Upload 1 LFS files: 100%|██████████| 1/1 [01:56<00:00, 116.68s/it]\n",
      "Creating parquet from Arrow format: 100%|██████████| 1/1 [00:02<00:00,  2.03s/ba]40.48s/it]  \n",
      "Upload 1 LFS files: 100%|██████████| 1/1 [02:19<00:00, 139.02s/it]\n",
      "Creating parquet from Arrow format: 100%|██████████| 1/1 [00:02<00:00,  2.00s/ba]43.09s/it]\n",
      "Upload 1 LFS files: 100%|██████████| 1/1 [02:05<00:00, 125.21s/it]\n",
      "Creating parquet from Arrow format: 100%|██████████| 1/1 [00:01<00:00,  1.92s/ba]40.77s/it]\n",
      "Upload 1 LFS files: 100%|██████████| 1/1 [02:14<00:00, 134.20s/it]\n",
      "Creating parquet from Arrow format: 100%|██████████| 1/1 [00:02<00:00,  2.34s/ba]42.09s/it]\n",
      "Upload 1 LFS files: 100%|██████████| 1/1 [02:18<00:00, 138.83s/it]\n",
      "Creating parquet from Arrow format: 100%|██████████| 1/1 [00:01<00:00,  1.65s/ba]44.54s/it]\n",
      "Upload 1 LFS files: 100%|██████████| 1/1 [02:15<00:00, 135.01s/it]\n",
      "Creating parquet from Arrow format: 100%|██████████| 1/1 [00:01<00:00,  1.57s/ba]44.31s/it]\n",
      "Upload 1 LFS files: 100%|██████████| 1/1 [01:46<00:00, 106.49s/it]\n",
      "Creating parquet from Arrow format: 100%|██████████| 1/1 [00:01<00:00,  1.70s/ba]35.71s/it]\n",
      "Upload 1 LFS files: 100%|██████████| 1/1 [02:15<00:00, 135.86s/it]\n",
      "Creating parquet from Arrow format: 100%|██████████| 1/1 [00:01<00:00,  1.95s/ba]38.40s/it]\n",
      "Upload 1 LFS files: 100%|██████████| 1/1 [02:21<00:00, 141.81s/it]\n",
      "Creating parquet from Arrow format: 100%|██████████| 1/1 [00:01<00:00,  1.22s/ba]42.26s/it]\n",
      "Upload 1 LFS files: 100%|██████████| 1/1 [01:43<00:00, 103.89s/it]\n",
      "Creating parquet from Arrow format: 100%|██████████| 1/1 [00:01<00:00,  1.94s/ba]33.40s/it]\n",
      "Upload 1 LFS files: 100%|██████████| 1/1 [02:25<00:00, 145.03s/it]\n",
      "Creating parquet from Arrow format: 100%|██████████| 1/1 [00:01<00:00,  1.87s/ba]39.80s/it]\n",
      "Upload 1 LFS files: 100%|██████████| 1/1 [02:14<00:00, 134.04s/it]\n",
      "Creating parquet from Arrow format: 100%|██████████| 1/1 [00:02<00:00,  2.05s/ba]40.91s/it]\n",
      "Upload 1 LFS files: 100%|██████████| 1/1 [03:29<00:00, 209.48s/it]\n",
      "Creating parquet from Arrow format: 100%|██████████| 1/1 [00:01<00:00,  1.51s/ba]64.67s/it]\n",
      "Upload 1 LFS files: 100%|██████████| 1/1 [02:27<00:00, 147.34s/it]\n",
      "Creating parquet from Arrow format: 100%|██████████| 1/1 [00:01<00:00,  1.84s/ba]62.27s/it]\n",
      "Upload 1 LFS files: 100%|██████████| 1/1 [02:38<00:00, 158.26s/it]\n",
      "Creating parquet from Arrow format: 100%|██████████| 1/1 [00:01<00:00,  1.86s/ba] 163.93s/it]\n",
      "Upload 1 LFS files: 100%|██████████| 1/1 [02:21<00:00, 141.28s/it]\n",
      "Creating parquet from Arrow format: 100%|██████████| 1/1 [00:01<00:00,  1.48s/ba] 160.08s/it]\n",
      "Upload 1 LFS files: 100%|██████████| 1/1 [01:55<00:00, 115.17s/it]\n",
      "Creating parquet from Arrow format: 100%|██████████| 1/1 [00:01<00:00,  1.94s/ba] 149.31s/it]\n",
      "Upload 1 LFS files: 100%|██████████| 1/1 [02:19<00:00, 139.38s/it]\n",
      "Creating parquet from Arrow format: 100%|██████████| 1/1 [00:01<00:00,  1.79s/ba] 149.38s/it]\n",
      "Upload 1 LFS files: 100%|██████████| 1/1 [02:13<00:00, 133.49s/it]\n",
      "Creating parquet from Arrow format: 100%|██████████| 1/1 [00:01<00:00,  1.83s/ba] 147.49s/it]\n",
      "Upload 1 LFS files: 100%|██████████| 1/1 [02:29<00:00, 149.51s/it]\n",
      "Creating parquet from Arrow format: 100%|██████████| 1/1 [00:01<00:00,  1.88s/ba] 151.17s/it]\n",
      "Upload 1 LFS files: 100%|██████████| 1/1 [02:23<00:00, 143.16s/it]\n",
      "Creating parquet from Arrow format: 100%|██████████| 1/1 [00:01<00:00,  1.84s/ba] 151.70s/it]\n",
      "Upload 1 LFS files: 100%|██████████| 1/1 [02:10<00:00, 130.12s/it]\n",
      "Creating parquet from Arrow format: 100%|██████████| 1/1 [00:01<00:00,  1.87s/ba] 148.24s/it]\n",
      "Upload 1 LFS files: 100%|██████████| 1/1 [02:23<00:00, 143.10s/it]\n",
      "Creating parquet from Arrow format: 100%|██████████| 1/1 [00:01<00:00,  1.84s/ba] 149.63s/it]\n",
      "Upload 1 LFS files: 100%|██████████| 1/1 [02:16<00:00, 136.96s/it]\n",
      "Creating parquet from Arrow format: 100%|██████████| 1/1 [00:01<00:00,  1.78s/ba] 148.78s/it]\n",
      "Upload 1 LFS files: 100%|██████████| 1/1 [02:21<00:00, 141.56s/it]\n",
      "Pushing dataset shards to the dataset hub: 100%|██████████| 36/36 [1:26:41<00:00, 144.49s/it]\n",
      "Pushing split test to the Hub.\n",
      "Creating parquet from Arrow format: 100%|██████████| 1/1 [00:00<00:00,  1.02ba/s]\n",
      "Upload 1 LFS files: 100%|██████████| 1/1 [01:13<00:00, 73.78s/it]\n",
      "Pushing dataset shards to the dataset hub: 100%|██████████| 1/1 [01:15<00:00, 75.95s/it]\n",
      "Pushing split validation to the Hub.\n",
      "Creating parquet from Arrow format: 100%|██████████| 1/1 [00:00<00:00,  1.02ba/s]\n",
      "Upload 1 LFS files: 100%|██████████| 1/1 [00:48<00:00, 48.07s/it]\n",
      "Pushing dataset shards to the dataset hub: 100%|██████████| 1/1 [00:50<00:00, 50.49s/it]\n"
     ]
    }
   ],
   "source": [
    "dataset = load_dataset(\"s-r-5o\", name='SAA_s-r-5o')\n",
    "dataset.push_to_hub(\"reralle/s-r-5o\", private=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Resolving data files: 100%|██████████| 7580/7580 [00:00<00:00, 30938.91it/s]\n",
      "Resolving data files: 100%|██████████| 300/300 [00:00<00:00, 300379.85it/s]\n",
      "Resolving data files: 100%|██████████| 300/300 [00:00<00:00, 299950.23it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading and preparing dataset audiofolder/s-r-5c to C:/Users/Rita/.cache/huggingface/datasets/audiofolder/s-r-5c-4fbd18b3f7f407f7/0.0.0/6cbdd16f8688354c63b4e2a36e1585d05de285023ee6443ffd71c4182055c0fc...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading data files: 100%|██████████| 7580/7580 [00:00<00:00, 11048.89it/s]\n",
      "Downloading data files: 0it [00:00, ?it/s]\n",
      "Extracting data files: 0it [00:00, ?it/s]\n",
      "Downloading data files: 100%|██████████| 300/300 [00:00<00:00, 10699.85it/s]\n",
      "Downloading data files: 0it [00:00, ?it/s]\n",
      "Extracting data files: 0it [00:00, ?it/s]\n",
      "Downloading data files: 100%|██████████| 300/300 [00:00<00:00, 11101.23it/s]\n",
      "Downloading data files: 0it [00:00, ?it/s]\n",
      "Extracting data files: 0it [00:00, ?it/s]\n",
      "                                                                  \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset audiofolder downloaded and prepared to C:/Users/Rita/.cache/huggingface/datasets/audiofolder/s-r-5c-4fbd18b3f7f407f7/0.0.0/6cbdd16f8688354c63b4e2a36e1585d05de285023ee6443ffd71c4182055c0fc. Subsequent calls will reuse this data.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3/3 [00:00<00:00, 30.84it/s]\n",
      "Pushing split train to the Hub.\n",
      "Creating parquet from Arrow format: 100%|██████████| 1/1 [00:01<00:00,  1.65s/ba]\n",
      "Upload 1 LFS files: 100%|██████████| 1/1 [02:05<00:00, 125.65s/it]\n",
      "Creating parquet from Arrow format: 100%|██████████| 1/1 [00:01<00:00,  1.45s/ba]8.97s/it]\n",
      "Upload 1 LFS files: 100%|██████████| 1/1 [01:24<00:00, 84.08s/it]\n",
      "Creating parquet from Arrow format: 100%|██████████| 1/1 [00:01<00:00,  1.59s/ba]7.57s/it]\n",
      "Upload 1 LFS files: 100%|██████████| 1/1 [01:20<00:00, 80.97s/it]\n",
      "Creating parquet from Arrow format: 100%|██████████| 1/1 [00:01<00:00,  1.68s/ba].41s/it] \n",
      "Upload 1 LFS files: 100%|██████████| 1/1 [01:23<00:00, 83.40s/it]\n",
      "Creating parquet from Arrow format: 100%|██████████| 1/1 [00:01<00:00,  1.61s/ba].28s/it]\n",
      "Upload 1 LFS files: 100%|██████████| 1/1 [01:22<00:00, 82.83s/it]\n",
      "Creating parquet from Arrow format: 100%|██████████| 1/1 [00:01<00:00,  1.44s/ba].47s/it]\n",
      "Upload 1 LFS files: 100%|██████████| 1/1 [01:14<00:00, 74.16s/it]\n",
      "Creating parquet from Arrow format: 100%|██████████| 1/1 [00:01<00:00,  1.68s/ba].39s/it]\n",
      "Upload 1 LFS files: 100%|██████████| 1/1 [01:22<00:00, 82.55s/it]\n",
      "Creating parquet from Arrow format: 100%|██████████| 1/1 [00:01<00:00,  1.59s/ba].68s/it]\n",
      "Upload 1 LFS files: 100%|██████████| 1/1 [01:18<00:00, 78.15s/it]\n",
      "Creating parquet from Arrow format: 100%|██████████| 1/1 [00:01<00:00,  1.32s/ba].73s/it]\n",
      "Upload 1 LFS files: 100%|██████████| 1/1 [01:11<00:00, 71.22s/it]\n",
      "Creating parquet from Arrow format: 100%|██████████| 1/1 [00:01<00:00,  1.59s/ba].55s/it]\n",
      "Upload 1 LFS files: 100%|██████████| 1/1 [01:26<00:00, 86.23s/it]\n",
      "Creating parquet from Arrow format: 100%|██████████| 1/1 [00:01<00:00,  1.67s/ba]9.15s/it]\n",
      "Upload 1 LFS files: 100%|██████████| 1/1 [01:29<00:00, 89.30s/it]\n",
      "Creating parquet from Arrow format: 100%|██████████| 1/1 [00:01<00:00,  1.62s/ba]1.89s/it]\n",
      "Upload 1 LFS files: 100%|██████████| 1/1 [01:33<00:00, 93.10s/it]\n",
      "Creating parquet from Arrow format: 100%|██████████| 1/1 [00:01<00:00,  1.41s/ba]4.83s/it]\n",
      "Upload 1 LFS files: 100%|██████████| 1/1 [01:19<00:00, 79.96s/it]\n",
      "Creating parquet from Arrow format: 100%|██████████| 1/1 [00:01<00:00,  1.47s/ba]2.85s/it]\n",
      "Upload 1 LFS files: 100%|██████████| 1/1 [01:28<00:00, 88.61s/it]\n",
      "Pushing dataset shards to the dataset hub: 100%|██████████| 14/14 [21:54<00:00, 93.92s/it]\n",
      "Pushing split test to the Hub.\n",
      "Creating parquet from Arrow format: 100%|██████████| 1/1 [00:00<00:00,  1.27ba/s]\n",
      "Upload 1 LFS files: 100%|██████████| 1/1 [00:51<00:00, 51.34s/it]\n",
      "Pushing dataset shards to the dataset hub: 100%|██████████| 1/1 [00:53<00:00, 53.54s/it]\n",
      "Pushing split validation to the Hub.\n",
      "Creating parquet from Arrow format: 100%|██████████| 1/1 [00:00<00:00,  1.27ba/s]\n",
      "Upload 1 LFS files: 100%|██████████| 1/1 [00:47<00:00, 47.78s/it]\n",
      "Pushing dataset shards to the dataset hub: 100%|██████████| 1/1 [00:49<00:00, 49.85s/it]\n"
     ]
    }
   ],
   "source": [
    "dataset = load_dataset(\"s-r-5c\", name='SAA_s-r-5c')\n",
    "dataset.push_to_hub(\"reralle/s-r-5c\", private=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Resolving data files: 100%|██████████| 15160/15160 [00:00<00:00, 18748.52it/s]\n",
      "Resolving data files: 100%|██████████| 300/300 [00:00<00:00, 300308.16it/s]\n",
      "Resolving data files: 100%|██████████| 300/300 [00:00<00:00, 149778.74it/s]\n",
      "Found cached dataset audiofolder (C:/Users/Rita/.cache/huggingface/datasets/audiofolder/s-r-10c-11fb54e2e31918cf/0.0.0/6cbdd16f8688354c63b4e2a36e1585d05de285023ee6443ffd71c4182055c0fc)\n",
      "100%|██████████| 3/3 [00:00<00:00, 12.27it/s]\n",
      "Pushing split train to the Hub.\n",
      "Creating parquet from Arrow format: 100%|██████████| 1/1 [00:01<00:00,  1.67s/ba].33s/it]\n",
      "Upload 1 LFS files: 100%|██████████| 1/1 [01:04<00:00, 64.72s/it]\n",
      "Creating parquet from Arrow format: 100%|██████████| 1/1 [00:01<00:00,  1.76s/ba].17s/it]\n",
      "Upload 1 LFS files: 100%|██████████| 1/1 [01:07<00:00, 67.57s/it]\n",
      "Creating parquet from Arrow format: 100%|██████████| 1/1 [00:01<00:00,  1.92s/ba].95s/it]\n",
      "Upload 1 LFS files: 100%|██████████| 1/1 [01:14<00:00, 74.07s/it]\n",
      "Creating parquet from Arrow format: 100%|██████████| 1/1 [00:01<00:00,  1.88s/ba].53s/it]\n",
      "Upload 1 LFS files: 100%|██████████| 1/1 [01:27<00:00, 87.05s/it]\n",
      "Creating parquet from Arrow format: 100%|██████████| 1/1 [00:01<00:00,  1.96s/ba].00s/it]\n",
      "Upload 1 LFS files: 100%|██████████| 1/1 [01:26<00:00, 86.42s/it]\n",
      "Creating parquet from Arrow format: 100%|██████████| 1/1 [00:01<00:00,  1.79s/ba]7.37s/it]\n",
      "Upload 1 LFS files: 100%|██████████| 1/1 [01:13<00:00, 73.90s/it]\n",
      "Creating parquet from Arrow format: 100%|██████████| 1/1 [00:01<00:00,  1.56s/ba]9.32s/it]\n",
      "Upload 1 LFS files: 100%|██████████| 1/1 [01:15<00:00, 75.21s/it]\n",
      "Creating parquet from Arrow format: 100%|██████████| 1/1 [00:01<00:00,  1.68s/ba]0.84s/it]\n",
      "Upload 1 LFS files: 100%|██████████| 1/1 [01:16<00:00, 76.52s/it]\n",
      "Creating parquet from Arrow format: 100%|██████████| 1/1 [00:01<00:00,  1.66s/ba]2.30s/it]\n",
      "Upload 1 LFS files: 100%|██████████| 1/1 [01:18<00:00, 78.34s/it]\n",
      "Creating parquet from Arrow format: 100%|██████████| 1/1 [00:01<00:00,  1.74s/ba]3.89s/it]\n",
      "Upload 1 LFS files: 100%|██████████| 1/1 [01:18<00:00, 78.55s/it]\n",
      "Creating parquet from Arrow format: 100%|██████████| 1/1 [00:01<00:00,  1.98s/ba]5.40s/it]\n",
      "Upload 1 LFS files: 100%|██████████| 1/1 [01:19<00:00, 79.28s/it]\n",
      "Creating parquet from Arrow format: 100%|██████████| 1/1 [00:01<00:00,  1.46s/ba]6.54s/it]\n",
      "Upload 1 LFS files: 100%|██████████| 1/1 [01:05<00:00, 65.25s/it]\n",
      "Creating parquet from Arrow format: 100%|██████████| 1/1 [00:01<00:00,  1.64s/ba]3.01s/it]\n",
      "Upload 1 LFS files: 100%|██████████| 1/1 [01:12<00:00, 72.79s/it]\n",
      "Creating parquet from Arrow format: 100%|██████████| 1/1 [00:01<00:00,  1.72s/ba]2.82s/it]\n",
      "Upload 1 LFS files: 100%|██████████| 1/1 [01:21<00:00, 81.49s/it]\n",
      "Creating parquet from Arrow format: 100%|██████████| 1/1 [00:01<00:00,  1.83s/ba]5.42s/it]\n",
      "Upload 1 LFS files: 100%|██████████| 1/1 [01:19<00:00, 79.44s/it]\n",
      "Creating parquet from Arrow format: 100%|██████████| 1/1 [00:01<00:00,  1.97s/ba]6.60s/it]\n",
      "Upload 1 LFS files: 100%|██████████| 1/1 [01:17<00:00, 77.77s/it]\n",
      "Creating parquet from Arrow format: 100%|██████████| 1/1 [00:01<00:00,  1.97s/ba]6.98s/it]\n",
      "Upload 1 LFS files: 100%|██████████| 1/1 [01:16<00:00, 76.69s/it]\n",
      "Creating parquet from Arrow format: 100%|██████████| 1/1 [00:01<00:00,  1.81s/ba]6.83s/it]\n",
      "Upload 1 LFS files: 100%|██████████| 1/1 [01:15<00:00, 75.96s/it]\n",
      "Creating parquet from Arrow format: 100%|██████████| 1/1 [00:01<00:00,  1.90s/ba]6.50s/it]\n",
      "Upload 1 LFS files: 100%|██████████| 1/1 [01:25<00:00, 85.84s/it]\n",
      "Creating parquet from Arrow format: 100%|██████████| 1/1 [00:01<00:00,  1.54s/ba]9.17s/it]\n",
      "Upload 1 LFS files: 100%|██████████| 1/1 [01:11<00:00, 71.39s/it]\n",
      "Creating parquet from Arrow format: 100%|██████████| 1/1 [00:01<00:00,  1.86s/ba]6.58s/it]\n",
      "Upload 1 LFS files: 100%|██████████| 1/1 [01:06<00:00, 66.90s/it]\n",
      "Creating parquet from Arrow format: 100%|██████████| 1/1 [00:01<00:00,  1.83s/ba]3.65s/it]\n",
      "Upload 1 LFS files: 100%|██████████| 1/1 [01:10<00:00, 70.59s/it]\n",
      "Pushing dataset shards to the dataset hub: 100%|██████████| 27/27 [31:43<00:00, 70.50s/it]\n",
      "Pushing split test to the Hub.\n",
      "Creating parquet from Arrow format: 100%|██████████| 1/1 [00:00<00:00,  1.12ba/s]\n",
      "Upload 1 LFS files: 100%|██████████| 1/1 [00:51<00:00, 51.36s/it]\n",
      "Pushing dataset shards to the dataset hub: 100%|██████████| 1/1 [00:53<00:00, 53.62s/it]\n",
      "Pushing split validation to the Hub.\n",
      "Creating parquet from Arrow format: 100%|██████████| 1/1 [00:00<00:00,  1.07ba/s]\n",
      "Upload 1 LFS files: 100%|██████████| 1/1 [00:48<00:00, 48.04s/it]\n",
      "Pushing dataset shards to the dataset hub: 100%|██████████| 1/1 [00:50<00:00, 50.34s/it]\n"
     ]
    }
   ],
   "source": [
    "dataset = load_dataset(\"s-r-10c\", name='SAA_s-r-10c')\n",
    "dataset.push_to_hub(\"reralle/s-r-10c\", private=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_df_with_s_r_10c.to_excel('saa_april.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "d6282b6e4d677aa4f061341f82854aa406aca119071d71869111bf6890f340ff"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
